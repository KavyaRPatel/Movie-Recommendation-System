{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%HTML\n<style type=\"text/css\">\n                                       \ndiv.h2 {\n    background-color: #3E5AE6;\n    background-image: linear-gradient(120deg, #3E5AE6, #A37CE6);\n    text-align: left;\n    color: white;              \n    padding:9px;\n    padding-right: 100px; \n    font-size: 20px; \n    max-width: 1500px; \n    margin: auto; \n    margin-top: 40px; \n}                                  \n                                      \nbody {\n  font-size: 12px;\n}    \n                                                                               \ndiv.h3 {\n    color: #3E5AE6; \n    font-size: 18px; \n    margin-top: 20px; \n    margin-bottom:4px;\n}\n                                     \ndiv.h4 {\n    color: #159957;\n    font-size: 15px; \n    margin-top: 20px; \n    margin-bottom: 8px;\n}\n                                         \nspan.note {\n    font-size: 5; \n    color: gray; \n    font-style: italic;\n}\n                                        \nhr {\n    display: block; \n    color: gray\n    height: 1px; \n    border: 0; \n    border-top: 1px solid;\n}\n  \n                                      \nhr.light {\n    display: block; \n    color: lightgray\n    height: 1px; \n    border: 0; \n    border-top: 1px solid;\n}   \n                                         \ntable.dataframe th \n{\n    border: 1px darkgray solid;\n    color: black;\n    background-color: white;\n}\n                                       \ntable.dataframe td \n{\n    border: 1px darkgray solid;\n    color: black;\n    background-color: white;\n    font-size: 14px;\n    text-align: center;\n} \n                                         \ntable.rules th \n{\n    border: 1px darkgray solid;\n    color: black;\n    background-color: white;\n    font-size: 14px;\n}\n                                          \ntable.rules td \n{\n    border: 1px darkgray solid;\n    color: black;\n    background-color: white;\n    font-size: 13px;\n    text-align: center;\n} \n                                      \n                                      \ntable.rules tr.best\n{\n    color: green;\n}    \n                                       \n.output { \n    align-items: center; \n}\n                                      \n.output_png {\n    display: table-cell;\n    text-align: center;\n    margin:auto;\n}                                          \n                                                                                                                                                                                                                                      \n</style>  ","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-05-01T01:39:41.007055Z","iopub.execute_input":"2022-05-01T01:39:41.007596Z","iopub.status.idle":"2022-05-01T01:39:41.01653Z","shell.execute_reply.started":"2022-05-01T01:39:41.007559Z","shell.execute_reply":"2022-05-01T01:39:41.015692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Movie Recommendation System using Spark**","metadata":{}},{"cell_type":"markdown","source":"# **Group Members:**\n\n1. Sanya Zaveri AU1920064\n2. Kavya Patel AU1940144\n3. Kairavi Shah AU1940177","metadata":{}},{"cell_type":"markdown","source":"<br>\n<a id='bkground'></a>\n<div class=\"h2\"><center>Introduction</center></div>\n<br>\n\nRecommendation systems having been much present right now, there are so many approaches to make and improve they.<br>\nWe can find they in online shops, music streaming and video streaming services.<br>\nIn this Kernel, I make an EDA on [The Movies Dataset](https://www.kaggle.com/rounakbanik/the-movies-dataset) and got the data used for movie ratings to build a Recommendation System with Alternating Least Square (ALS), with it, it will be possible make a user based system or a item based system.<br>\n<br>\nFor this job, I will work with Pandas Dataframes, visualizations with Altair, printable text with BeautifulText and PySpark for ALS.<br>\nThis Kernel is inspired by the great work made by these guys:\n* @tombresee for made this awesome [kernel](https://www.kaggle.com/tombresee/next-gen-eda) with great use of HTML.\n* @artgor with his great kernels using Altair for Data Visualization, [here's an example](https://www.kaggle.com/artgor/dota-eda-fe-and-models)\n* @vchulski for made this [kernel](https://www.kaggle.com/vchulski/tutorial-collaborative-filtering-with-pyspark) that explain so good how to use ALS with PySpark.\n\nAlright, let's start installing all nedeed modules and imports, you can in the buttons to see the code or output.","metadata":{}},{"cell_type":"code","source":"!pip install -U vega_datasets notebook vega","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-05-01T01:39:41.018509Z","iopub.execute_input":"2022-05-01T01:39:41.019103Z","iopub.status.idle":"2022-05-01T01:40:07.61113Z","shell.execute_reply.started":"2022-05-01T01:39:41.019059Z","shell.execute_reply":"2022-05-01T01:40:07.609805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install ujson","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-05-01T01:40:07.612808Z","iopub.execute_input":"2022-05-01T01:40:07.613094Z","iopub.status.idle":"2022-05-01T01:40:13.218083Z","shell.execute_reply.started":"2022-05-01T01:40:07.613063Z","shell.execute_reply":"2022-05-01T01:40:13.216994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%env JOBLIB_TEMP_FOLDER=/tmp\n!pip install pyspark","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-05-01T01:40:13.219587Z","iopub.execute_input":"2022-05-01T01:40:13.21998Z","iopub.status.idle":"2022-05-01T01:40:54.162247Z","shell.execute_reply.started":"2022-05-01T01:40:13.219934Z","shell.execute_reply":"2022-05-01T01:40:54.161339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\npd.set_option('display.max_columns', 8)\nimport os\nimport gc\nimport ujson as json\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport matplotlib.patches as patches\nimport seaborn as sns\n\nimport plotly as py\nimport plotly.express as px\nimport plotly.graph_objs as go\nfrom plotly.subplots import make_subplots\nfrom plotly.offline import download_plotlyjs\nfrom plotly.offline import init_notebook_mode\nfrom plotly.offline import plot,iplot\n\ninit_notebook_mode(connected=True)\n\nimport altair as alt\nfrom altair.vega import v5\nfrom IPython.display import HTML\nalt.renderers.enable('notebook')\n\nfrom IPython.display import HTML\nfrom IPython.display import Image\nfrom IPython.display import display\nfrom IPython.core.display import display\nfrom IPython.core.display import HTML\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nplt.style.use('seaborn') \ncolor_pal = [x['color'] for x in plt.rcParams['axes.prop_cycle']]\n%config InlineBackend.figure_format = 'svg'  \nth_props = [('font-size', '13px'), ('background-color', 'white'), ('color', '#666666')]\ntd_props = [('font-size', '15px'), ('background-color', 'white')]\nstyles = [dict(selector=\"td\", props=td_props), dict(selector=\"th\", props=th_props)]\n\nSMALL_SIZE = 8\nMEDIUM_SIZE = 10\nBIGGER_SIZE = 12\nplt.rc('font', size=SMALL_SIZE)          # controls default text sizes\nplt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\nplt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\nplt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\nplt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\nplt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\nplt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n\nDATA_PATH = '../input/the-movies-dataset/'","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2022-05-01T01:40:54.166136Z","iopub.execute_input":"2022-05-01T01:40:54.166495Z","iopub.status.idle":"2022-05-01T01:40:56.496855Z","shell.execute_reply.started":"2022-05-01T01:40:54.166461Z","shell.execute_reply":"2022-05-01T01:40:56.496054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# using ideas from this kernel: https://www.kaggle.com/notslush/altair-visualization-2018-stackoverflow-survey\ndef prepare_altair():\n    \"\"\"\n    Helper function to prepare altair for working.\n    \"\"\"\n\n    vega_url = 'https://cdn.jsdelivr.net/npm/vega@' + v5.SCHEMA_VERSION\n    vega_lib_url = 'https://cdn.jsdelivr.net/npm/vega-lib'\n    vega_lite_url = 'https://cdn.jsdelivr.net/npm/vega-lite@' + alt.SCHEMA_VERSION\n    vega_embed_url = 'https://cdn.jsdelivr.net/npm/vega-embed@3'\n    noext = \"?noext\"\n    \n    paths = {\n        'vega': vega_url + noext,\n        'vega-lib': vega_lib_url + noext,\n        'vega-lite': vega_lite_url + noext,\n        'vega-embed': vega_embed_url + noext\n    }\n    \n    workaround = f\"\"\"    requirejs.config({{\n        baseUrl: 'https://cdn.jsdelivr.net/npm/',\n        paths: {paths}\n    }});\n    \"\"\"\n    \n    return workaround\n    \ndef add_autoincrement(render_func):\n    # Keep track of unique <div/> IDs\n    cache = {}\n    def wrapped(chart, id=\"vega-chart\", autoincrement=True):\n        if autoincrement:\n            if id in cache:\n                counter = 1 + cache[id]\n                cache[id] = counter\n            else:\n                cache[id] = 0\n            actual_id = id if cache[id] == 0 else id + '-' + str(cache[id])\n        else:\n            if id not in cache:\n                cache[id] = 0\n            actual_id = id\n        return render_func(chart, id=actual_id)\n    # Cache will stay outside and \n    return wrapped\n           \n@add_autoincrement\ndef render(chart, id=\"vega-chart\"):\n    \"\"\"\n    Helper function to plot altair visualizations.\n    \"\"\"\n    chart_str = \"\"\"\n    <div id=\"{id}\"></div><script>\n    require([\"vega-embed\"], function(vg_embed) {{\n        const spec = {chart};     \n        vg_embed(\"#{id}\", spec, {{defaultStyle: true}}).catch(console.warn);\n        console.log(\"anything?\");\n    }});\n    console.log(\"really...anything?\");\n    </script>\n    \"\"\"\n    return HTML(\n        chart_str.format(\n            id=id,\n            chart=json.dumps(chart) if isinstance(chart, dict) else chart.to_json(indent=None)\n        )\n    )\n\n# setting up altair\nworkaround = prepare_altair()\nHTML(\"\".join((\n    \"<script>\",\n    workaround,\n    \"</script>\",\n)))","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-05-01T01:40:56.499202Z","iopub.execute_input":"2022-05-01T01:40:56.499442Z","iopub.status.idle":"2022-05-01T01:40:56.513538Z","shell.execute_reply.started":"2022-05-01T01:40:56.499417Z","shell.execute_reply":"2022-05-01T01:40:56.512946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It's time to take a look in all files provided by the dataset.","metadata":{}},{"cell_type":"code","source":"print('Data Files in Directory')\nprint(os.listdir(DATA_PATH))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-01T01:40:56.514811Z","iopub.execute_input":"2022-05-01T01:40:56.515083Z","iopub.status.idle":"2022-05-01T01:40:56.536041Z","shell.execute_reply.started":"2022-05-01T01:40:56.515056Z","shell.execute_reply":"2022-05-01T01:40:56.535129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For now, I will ignore all small dataset versions.<br>\nTime to import relvant (Ratings, Links and Metadata) files and check the data.","metadata":{}},{"cell_type":"code","source":"ratings = pd.read_csv(DATA_PATH+'ratings.csv')\nlinks = pd.read_csv(DATA_PATH+'links.csv')\nmetadata = pd.read_csv(DATA_PATH+'movies_metadata.csv')","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_kg_hide-input":true,"_kg_hide-output":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2022-05-01T01:40:56.537562Z","iopub.execute_input":"2022-05-01T01:40:56.53817Z","iopub.status.idle":"2022-05-01T01:41:12.196026Z","shell.execute_reply.started":"2022-05-01T01:40:56.53811Z","shell.execute_reply":"2022-05-01T01:41:12.19511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function that I wrote to print all relevant infos in dataset\nimport io\n\ndef get_df_info(df):\n    display(df.head(3))\n    buf = io.StringIO()\n    df.info(buf=buf)\n    info = buf.getvalue().split('\\n')[-2]\n    display(f'Number of Rows: {df.shape[0]}, Number of Columns: {df.shape[1]}')\n    display('Data Types')\n    df_types = df.dtypes\n    df_types = pd.DataFrame({'Column':df_types.index, 'Type':df_types.values})\n    display(df_types) \n    display(info)\n    missing = df.isnull().sum().sort_values(ascending=False)\n    display('Missing Values')\n    if missing.values.sum() == 0:\n        display('No Missing Values')\n    else:\n        missing = missing[missing > 0]\n        missing = pd.DataFrame({'Column' : missing.index, 'Missing Values' : missing.values})\n        display(missing)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-05-01T01:41:12.197168Z","iopub.execute_input":"2022-05-01T01:41:12.197378Z","iopub.status.idle":"2022-05-01T01:41:12.205172Z","shell.execute_reply.started":"2022-05-01T01:41:12.197355Z","shell.execute_reply":"2022-05-01T01:41:12.204446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='bkground'></a>\n<div class=\"h3\"><center>Ratings Content</center></div>","metadata":{}},{"cell_type":"code","source":"get_df_info(ratings)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-01T01:41:12.206126Z","iopub.execute_input":"2022-05-01T01:41:12.206491Z","iopub.status.idle":"2022-05-01T01:41:12.492602Z","shell.execute_reply.started":"2022-05-01T01:41:12.206455Z","shell.execute_reply":"2022-05-01T01:41:12.491782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id='bkground'></a>\n<div class=\"h3\"><center>Metadata Content</center></div>","metadata":{}},{"cell_type":"code","source":"get_df_info(metadata)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-01T01:41:12.493568Z","iopub.execute_input":"2022-05-01T01:41:12.493788Z","iopub.status.idle":"2022-05-01T01:41:12.63547Z","shell.execute_reply.started":"2022-05-01T01:41:12.493763Z","shell.execute_reply":"2022-05-01T01:41:12.634508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In all the data info displayed, we can see that only ratings have a large memory usage, and I will use this dataset to make the recommendation system based on user ratings, the dataset have the relevant data like userId, movieId and ratings.<br>\nIt's important to say that the ratings dataset doesn't have any missing value, therefore, will not needed any treatment like data imputation or drop NA rows.<br>\nThe other datasets will be used for Exploratory Data Analysis.\n","metadata":{}},{"cell_type":"markdown","source":"<br>\n<a id='bkground'></a>\n<div class=\"h2\"><center>Exploratory Data Analysis</center></div>\n<br>","metadata":{}},{"cell_type":"markdown","source":"<div class=\"h3\">Let's start with the following approaches</div><br>\n* Rating Frequency.\n* Analysis of most rated movies.\n* World cloud with most common words.\n\nLet's start plotting an Histogram to see the rating distribution.","metadata":{}},{"cell_type":"code","source":"plt.rcParams['figure.figsize'] = (7, 6)\nplt.hist(ratings['rating'], bins=10);\nplt.title('Ratings Count', size=10)\nplt.xlabel('Rating')\nplt.ylabel('Frequency')\nplt.show();","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-01T01:41:12.637096Z","iopub.execute_input":"2022-05-01T01:41:12.637352Z","iopub.status.idle":"2022-05-01T01:41:13.405522Z","shell.execute_reply.started":"2022-05-01T01:41:12.637325Z","shell.execute_reply":"2022-05-01T01:41:13.404636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And for a better visualization, let's represent by a pie chart with the percent representation.","metadata":{}},{"cell_type":"code","source":"values = ratings.rating.value_counts()\nlabels = values.index\ncolors = ['red', 'blue', 'green', 'yellow', 'black']\ntrace = go.Pie(labels=labels, \n               values=values,\n                marker=dict(colors=colors) \n              )\nlayout = go.Layout(title='Ratings by Total Percent')\nfig = go.Figure(data=trace, layout=layout)\niplot(fig)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-01T01:41:13.407065Z","iopub.execute_input":"2022-05-01T01:41:13.407382Z","iopub.status.idle":"2022-05-01T01:41:14.979164Z","shell.execute_reply.started":"2022-05-01T01:41:13.407346Z","shell.execute_reply":"2022-05-01T01:41:14.978234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see most movies were rated with 4, on a scale of 1 to 5. A fewer movies (compared to the total dataset) were rated with low grades. <br>\nLet's see which movies were rated most times, taking the 10 most rated.","metadata":{}},{"cell_type":"code","source":"df_aux = ratings['movieId'].value_counts().reset_index().head(10).rename(columns={'index': 'movieId', 'movieId': 'count'})\ndf_aux['movieId'] = df_aux['movieId'].astype(str)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-01T01:41:14.980964Z","iopub.execute_input":"2022-05-01T01:41:14.981338Z","iopub.status.idle":"2022-05-01T01:41:15.811954Z","shell.execute_reply.started":"2022-05-01T01:41:14.981295Z","shell.execute_reply":"2022-05-01T01:41:15.811117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"render(alt.Chart(df_aux).mark_bar().encode(\n    x=alt.X('movieId:N', axis=alt.Axis(title='Movie ID'), sort=list(df_aux['movieId'].values)),\n    y=alt.Y('count:Q', axis=alt.Axis(title='Total Count')),\n    tooltip=['movieId', 'count']\n).properties(title='Movie Count', height=300, width=800).interactive())","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-01T01:41:15.813101Z","iopub.execute_input":"2022-05-01T01:41:15.81342Z","iopub.status.idle":"2022-05-01T01:41:15.946811Z","shell.execute_reply.started":"2022-05-01T01:41:15.813385Z","shell.execute_reply":"2022-05-01T01:41:15.946181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Time to discover which movies have this IDs.<br> \nLet's check the IDs on IMDB and get some info.","metadata":{}},{"cell_type":"code","source":"# Get the Movie on metadata\ndef get_movie_metadata(movieId):\n    metadata['imdb_id'] = metadata['imdb_id'].astype('category')\n    imdb_id = links[links['movieId'] == movieId]\n    imdb_id = imdb_id.imdbId.values[0]\n    if len(str(imdb_id)) == 7:\n        movie_rated = metadata[metadata['imdb_id'] == 'tt'+imdb_id.astype(str)]\n        df = movie_rated.loc[:,['title', 'overview', 'vote_average', 'release_date']]\n        return df.reset_index(drop=True)\n    elif len(str(imdb_id)) == 6:\n        movie_rated = metadata[metadata['imdb_id'] == 'tt0'+imdb_id.astype(str)]\n        df = movie_rated.loc[:,['title', 'overview', 'vote_average', 'release_date']]\n        return df.reset_index(drop=True)\n    elif len(str(imdb_id)) == 5:\n        movie_rated = metadata[metadata['imdb_id'] == 'tt00'+imdb_id.astype(str)]\n        df = movie_rated.loc[:,['title', 'overview', 'vote_average', 'release_date']]\n        return df.reset_index(drop=True)\n    elif len(str(imdb_id)) == 4:\n        movie_rated = metadata[metadata['imdb_id'] == 'tt000'+imdb_id.astype(str)]\n        df = movie_rated.loc[:,['title', 'overview', 'vote_average', 'release_date']]\n        return df.reset_index(drop=True)\n    elif len(str(imdb_id)) == 3:\n        movie_rated = metadata[metadata['imdb_id'] == 'tt0000'+imdb_id.astype(str)]\n        df = movie_rated.loc[:,['title', 'overview', 'vote_average', 'release_date']]\n        return df.reset_index(drop=True)\n    elif len(str(imdb_id)) == 2:\n        movie_rated = metadata[metadata['imdb_id'] == 'tt00000'+imdb_id.astype(str)]\n        df = movie_rated.loc[:,['title', 'overview', 'vote_average', 'release_date']]\n        return df.reset_index(drop=True)\n    elif len(str(imdb_id)) == 1:\n        movie_rated = metadata[metadata['imdb_id'] == 'tt000000'+imdb_id.astype(str)]\n        df = movie_rated.loc[:,['title', 'overview', 'vote_average', 'release_date']]\n        return df.reset_index(drop=True)\n    else:\n        pass\n# Get Movie List\ndef get_movie(df):\n    movieIdIdx = df['movieId'].values.astype(int)\n    df_aux_b = pd.DataFrame({'title': ['aaa'], \n                           'overview': ['bbb'], \n                           'vote_average': [1.7], \n                           'release_date': ['1999-01-01']\n        })\n    for i in movieIdIdx:\n        df_aux_b = df_aux_b.append(get_movie_metadata(i), ignore_index=True)\n\n    df_aux_b.drop(0, inplace=True)\n    df_aux_b['release_date'] = df_aux_b['release_date'].apply(lambda x : x.split('-')[0])\n    df_aux_b['release_date'] = df_aux_b['release_date'].astype(int)\n    df_aux_b.rename(columns={'release_date' : 'release_year'}, inplace=True)\n    return df_aux_b.reset_index(drop=True)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-01T01:41:15.948431Z","iopub.execute_input":"2022-05-01T01:41:15.948937Z","iopub.status.idle":"2022-05-01T01:41:15.966151Z","shell.execute_reply.started":"2022-05-01T01:41:15.948876Z","shell.execute_reply":"2022-05-01T01:41:15.965369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_movies = get_movie(df_aux)\ndf_movies","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-01T01:41:15.967439Z","iopub.execute_input":"2022-05-01T01:41:15.967889Z","iopub.status.idle":"2022-05-01T01:41:16.112593Z","shell.execute_reply.started":"2022-05-01T01:41:15.967848Z","shell.execute_reply":"2022-05-01T01:41:16.11167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nAnother curious information is that in the most rated movies, none have a rate above 9.0.<br>\nLet's expand it, let's get all the 1000 most rated movies and examine what words are frequent in they overviews.","metadata":{}},{"cell_type":"code","source":"df_aux = ratings['movieId'].value_counts().reset_index().head(1001).rename(columns={'index': 'movieId', 'movieId': 'count'})\ndf_aux['movieId'] = df_aux['movieId'].astype(str)\ndf_aux = get_movie(df_aux)\nget_df_info(df_aux)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-01T01:41:16.113922Z","iopub.execute_input":"2022-05-01T01:41:16.114185Z","iopub.status.idle":"2022-05-01T01:41:21.782781Z","shell.execute_reply.started":"2022-05-01T01:41:16.114157Z","shell.execute_reply":"2022-05-01T01:41:21.781995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Time to use Natural Language Processing (NLP) with NLTK module and transform everything in overview for lower case, word tokens and remove stopwords and make the Word Cloud.","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import RegexpTokenizer\nfrom wordcloud import WordCloud\n\nstop_words = set(stopwords.words('english'))\ntokenizer = RegexpTokenizer(r'\\w+')\n\ndf_aux['overview'] = df_aux.overview.apply(lambda x : x.lower())\ndf_aux['overview'] = df_aux.overview.apply(lambda x : tokenizer.tokenize(x))\ndf_aux['overview'] = df_aux.overview.apply(lambda x : [w for w in x if w not in stop_words])\ndf_aux['overview'] = df_aux.overview.apply(lambda x : ' '.join(x))\n\nword_count = df_aux.overview.apply(lambda x: pd.value_counts(x.split(\" \"))).sum(axis = 0).sort_values(ascending=False)\nword_count = pd.DataFrame({'word' : word_count.index, 'count': word_count.values})\n# Plot the WordCloud\nd = {}\nfor a, x in word_count.values:\n    d[a] = x\n\nwordcloud = WordCloud(background_color = 'white',\n                      max_words = 50,\n                      width = 2000,\n                      height = 2000)\nwordcloud.generate_from_frequencies(frequencies=d)\nplt.rcParams['figure.figsize'] = (10, 10)\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.title('Most Frequent words in TOP 1000 rated movies', fontsize = 25)\nplt.show();","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-01T01:41:21.784278Z","iopub.execute_input":"2022-05-01T01:41:21.784597Z","iopub.status.idle":"2022-05-01T01:41:30.525675Z","shell.execute_reply.started":"2022-05-01T01:41:21.784558Z","shell.execute_reply":"2022-05-01T01:41:30.522687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"del ratings, df_aux, df_movies\ngc.collect()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-05-01T01:41:30.527428Z","iopub.execute_input":"2022-05-01T01:41:30.528045Z","iopub.status.idle":"2022-05-01T01:41:30.653311Z","shell.execute_reply.started":"2022-05-01T01:41:30.527998Z","shell.execute_reply":"2022-05-01T01:41:30.652367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<br>\n<a id='bkground'></a>\n<div class=\"h2\"><center>Model using PySpark</center></div>\n<br>","metadata":{}},{"cell_type":"markdown","source":"Let's start importing all needed models and setting Spark.","metadata":{}},{"cell_type":"code","source":"import pyspark.sql.functions as sql_func\nfrom pyspark.sql.types import *\nfrom pyspark.ml.recommendation import ALS, ALSModel\nfrom pyspark.context import SparkContext\nfrom pyspark.sql.session import SparkSession\nfrom pyspark.mllib.evaluation import RegressionMetrics, RankingMetrics\nfrom pyspark.ml.evaluation import RegressionEvaluator\n\nsc = SparkContext('local')\nspark = SparkSession(sc)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-05-01T01:41:30.654712Z","iopub.execute_input":"2022-05-01T01:41:30.655037Z","iopub.status.idle":"2022-05-01T01:41:35.72343Z","shell.execute_reply.started":"2022-05-01T01:41:30.655005Z","shell.execute_reply":"2022-05-01T01:41:35.722271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create the Schema.","metadata":{}},{"cell_type":"code","source":"data_schema = StructType([\n    StructField('userId', IntegerType(), False),\n    StructField('movieId', IntegerType(), False),\n    StructField('rating', FloatType(), False),\n    StructField('timestamp',IntegerType(), False)\n])\nfinal_stat = spark.read.csv(\n    '/kaggle/input/the-movies-dataset/ratings.csv', header=True, schema=data_schema\n).cache()\n\nratings = (final_stat.select(\n    'userId',\n    'movieId',\n    'rating'\n)).cache()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-05-01T01:41:35.724898Z","iopub.execute_input":"2022-05-01T01:41:35.725246Z","iopub.status.idle":"2022-05-01T01:41:41.321238Z","shell.execute_reply.started":"2022-05-01T01:41:35.72518Z","shell.execute_reply":"2022-05-01T01:41:41.319118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Split in Train (70%) and Test (30%).","metadata":{}},{"cell_type":"code","source":"(training, test) = ratings.randomSplit([0.7, 0.3], seed=42)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-05-01T01:41:41.324985Z","iopub.execute_input":"2022-05-01T01:41:41.325715Z","iopub.status.idle":"2022-05-01T01:41:41.400794Z","shell.execute_reply.started":"2022-05-01T01:41:41.325669Z","shell.execute_reply":"2022-05-01T01:41:41.399417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And train the model, the evaluation will be made on test set using Mean Absolute Error (MAE).","metadata":{}},{"cell_type":"code","source":"als = ALS(\n          rank=30,\n          maxIter=4, \n          regParam=0.1,\n          userCol='userId', \n          itemCol='movieId', \n          ratingCol='rating',\n          coldStartStrategy='drop',\n          implicitPrefs=False\n         )\nmodel = als.fit(training)\n\npredictions = model.transform(test)\nevaluator = RegressionEvaluator(metricName='mae', labelCol='rating',\n                                predictionCol='prediction')\n\nmae = evaluator.evaluate(predictions)\nprint(f'MAE (Test) = {mae}')","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-05-01T01:41:41.403358Z","iopub.execute_input":"2022-05-01T01:41:41.404334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And finally, generate the Best recommendation for each user (User Based Recommendation System).\nThe movieId, the first element in recommendations vector, is the same of ratings dataframe.","metadata":{}},{"cell_type":"code","source":"model.recommendForAllUsers(1).show(5)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's see which movie was recommended for a particular userId.","metadata":{}},{"cell_type":"code","source":"get_movie_metadata(156589)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Show the most recommended user for each movie (Item Based Recommendation System).\nAgain, the movieId is the same of ratings dataframe.","metadata":{}},{"cell_type":"code","source":"model.recommendForAllItems(1).show(10)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"And this finish the work!","metadata":{}},{"cell_type":"markdown","source":"<br>\n<a id='bkground'></a>\n<div class=\"h2\"><center>End Notes</center></div>\n<br>","metadata":{}},{"cell_type":"markdown","source":"As the Kernel have memory and storage limitations, I couldn't get better results, but what I got was enough to demonstrate how to work with Recommendation Systems in PySpark.\n\nThanks for your reading!","metadata":{}}]}